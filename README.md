# 基于Scrapy+MongoDB爬取糗事百科
## 一、项目背景
为了帮助自己初步掌握Scrapy+MongoDB的使用，学习爬虫技术，完成入门。
## 二、项目目的
项目的主要目的是爬取糗事百科网站上的用户名、用户年龄、用户性别、段子内容、段子好笑数、段子评论数这6个主要的数据信息。 
选取这些数据的原因是，通过爬取这些用户信息，有助于我们去分析糗事百科上的用户性别比例、年龄比例以及热门段子等，从中去发现用户行为规律，辅助商业决策，实现数据的价值。当然这些都是后话了。不过一个要有的意识就是：爬取数据不是最终目的，实现数据的价值才是最终目的。因此数据的选取也是前期要认真考量的。
## 三、项目的环境配置
Win10(64)+Pycharm2018版+MongoDB3.4版+Anaconda(Python3.7)版+Robomongo 1.1-Beta 
## 四、项目实现
具体过程可以参看[博客](https://blog.csdn.net/qq_27283619/article/details/88699031)
## 五、项目总结
### 1. 项目优点
基本上实现了一开始自己设定的目标，爬取并存储了需要的信息，对比了一下数据，基本上没有发现错误。同时爬取的速度也还是比较快的。代码逻辑也较为清楚。
### 2. 项目不足
1） 因为糗事百科是动态更新的，一次性抓取的数据只有350条，这个样本量太小。如何实现动态抓取，做到每隔一段时间自动抓取一次，从而不断的累计数据。
2） 数据库中的数据去重问题，不断抓取的过程中，数据难免有重复，这个去重问题怎么实现？需要继续学习数据库的处理知识。
3） 数据抓取过来了，后续如何继续处理分析，如何作图，辅助我们做出决定。这方面还需要继续去研究。
